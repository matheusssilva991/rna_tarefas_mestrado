{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749e9c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../libs\"))\n",
    "sys.path.append(os.path.abspath(\"../utils\"))\n",
    "\n",
    "from levenberg_marquadt import levenberg_marquadt\n",
    "from normalize import  MinMaxNormalizer\n",
    "from loss_fn_tarefa4 import make_mse_loss_for_neuron\n",
    "from activations_fn import tanh_derivative\n",
    "from network import neuron\n",
    "\n",
    "pd.set_option('display.float_format', '{:.5f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77a74e5",
   "metadata": {},
   "source": [
    "# Ajuste de curva por otimização"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c8d133",
   "metadata": {},
   "source": [
    "## Carregar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037534c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento dos dados\n",
    "df = pd.read_excel('../data/Trabalho4dados.xlsx')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11523f5",
   "metadata": {},
   "source": [
    "## Calcular as funções de perda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6d8f5f",
   "metadata": {},
   "source": [
    "### Funções utilizadas para os cálculos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2939c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_residuals_fn(X1: np.ndarray, X2: np.ndarray, Y: np.ndarray, activation_fn=np.tanh):\n",
    "    def residuals_fn(w: np.ndarray) -> np.ndarray:\n",
    "        predictions = neuron(X1, X2, weights=w, activation_fn=activation_fn)\n",
    "        return Y - predictions\n",
    "    return residuals_fn\n",
    "\n",
    "\n",
    "def make_jacobian_fn(X1, X2, activation_fn=np.tanh, activation_deriv=tanh_derivative):\n",
    "    \"\"\"\n",
    "    Jacobiana genérica: derivada dos resíduos em relação aos pesos.\n",
    "    Funciona para qualquer função de ativação.\n",
    "    \"\"\"\n",
    "    def jacobian_fn(w):\n",
    "        X1_ = np.atleast_1d(X1)\n",
    "        X2_ = np.atleast_1d(X2)\n",
    "        X = np.stack([X1_, X2_, np.ones_like(X1_)], axis=1)\n",
    "        z = X @ w\n",
    "        phi_prime = activation_deriv(z)\n",
    "        J = -phi_prime[:, np.newaxis] * X  # cada linha: -φ'(z_i) * [x1, x2, 1]\n",
    "        return J\n",
    "    return jacobian_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4192a6",
   "metadata": {},
   "source": [
    "### Pré-processamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedadb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = df[['x1', 'x2']]\n",
    "y = df['y']\n",
    "\n",
    "# Criar os objetos para Padronização\n",
    "scaler = MinMaxNormalizer(-1, 1)\n",
    "scaler_y = MinMaxNormalizer(-1, 1)\n",
    "\n",
    "# Cria as cópias dos dados para padronizar\n",
    "scaled_features = features.copy()\n",
    "scaled_y = y.copy()\n",
    "\n",
    "# Ajusta os padronizadores aos dados\n",
    "scaler.fit(scaled_features)\n",
    "scaler_y.fit(scaled_y.to_frame())\n",
    "\n",
    "# Padroniza os dados\n",
    "scaled_features = scaler.normalize(scaled_features)\n",
    "scaled_y = scaler_y.normalize(scaled_y.to_frame()).squeeze()\n",
    "\n",
    "# initial_weights = np.random.randn(features.shape[1] + 1)  # 2 entradas + 1 bias\n",
    "initial_weights = np.zeros(features.shape[1] + 1)  # 2 entradas + 1 bias\n",
    "n_iterations = 10000\n",
    "tolerance = 1e-6\n",
    "alpha = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a0a850",
   "metadata": {},
   "source": [
    "### Rodar os experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec386dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_results = {}\n",
    "\n",
    "x1_scaled = scaled_features['x1'].values\n",
    "x2_scaled = scaled_features['x2'].values\n",
    "y_scaled_data = scaled_y.values\n",
    "\n",
    "# Função de custo e gradiente\n",
    "loss_function, grad_loss_function = make_mse_loss_for_neuron(x1_scaled, x2_scaled, y_scaled_data, activation_fn=np.tanh)\n",
    "\n",
    "# Função de residuos e jacobiana\n",
    "residuals_fn = make_residuals_fn(x1_scaled, x2_scaled, y_scaled_data, activation_fn=np.tanh)\n",
    "jacobian_fn = make_jacobian_fn(x1_scaled, x2_scaled, activation_fn=np.tanh, activation_deriv=tanh_derivative)\n",
    "\n",
    "# Treinar o modelo com Levenberg-Marquadt\n",
    "weights, losses, n_iters = levenberg_marquadt(\n",
    "    initial_weights, residuals_fn, loss_function, jacobian_fn,\n",
    "    alpha=alpha, alpha_variability=10, max_iter=n_iterations,\n",
    "    tolerance=tolerance, stopping_criteria=[1, 3]\n",
    ")\n",
    "\n",
    "# Desnormalizar os pesos finais\n",
    "final_raw_weights = weights[-1].copy()\n",
    "final_denorm_weights = scaler.desnormalize_weights(weights[-1])\n",
    "\n",
    "# Usar o neurônio com pesos desnormalizados\n",
    "x1_data = features['x1'].values\n",
    "x2_data = features['x2'].values\n",
    "y_hat = neuron(x1_data, x2_data, weights=final_denorm_weights, activation_fn=np.tanh)\n",
    "\n",
    "# Cálculo das métricas finais\n",
    "mse_final = np.mean((y - y_hat) ** 2)\n",
    "rmse_final = np.sqrt(mse_final)\n",
    "mae_final = np.mean(np.abs(y - y_hat))\n",
    "\n",
    "dict_results = {\n",
    "    'Feature_Set': \"MinMax(-1,1)\",\n",
    "    'Loss_Function': \"MSE\",\n",
    "    'Initial_Weights': str([f\"{w:.5f}\" for w in initial_weights.tolist()]),\n",
    "    'Raw_Weights': str([f\"{w:.5f}\" for w in final_raw_weights.tolist()]),\n",
    "    'Final_Weights': str([f\"{w:.5f}\" for w in final_denorm_weights.tolist()]),\n",
    "    'Final_Loss': losses[-1],\n",
    "    'MSE_Final': mse_final,\n",
    "    'RMSE_Final': rmse_final,\n",
    "    'MAE_Final': mae_final,\n",
    "    'Iterations': n_iters\n",
    "}\n",
    "\n",
    "# Criar DataFrame com um único registro\n",
    "df_result = pd.DataFrame([dict_results])  # Note os colchetes extras aqui\n",
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4636062a",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872089b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar figura 3D melhorada\n",
    "fig = go.Figure()\n",
    "\n",
    "# Adicionar superfície de predição para melhor visualização\n",
    "x1_range = np.linspace(min(x1_data), max(x1_data), 30)\n",
    "x2_range = np.linspace(min(x2_data), max(x2_data), 30)\n",
    "x1_grid, x2_grid = np.meshgrid(x1_range, x2_range)\n",
    "y_grid = np.zeros_like(x1_grid)\n",
    "\n",
    "# Calcular valores preditos para toda a superfície\n",
    "for i in range(x1_grid.shape[0]):\n",
    "    for j in range(x1_grid.shape[1]):\n",
    "        y_grid[i, j] = neuron(x1_grid[i, j], x2_grid[i, j], weights=final_denorm_weights, activation_fn=np.tanh)\n",
    "\n",
    "# Adicionar superfície de predição\n",
    "fig.add_trace(go.Surface(\n",
    "    x=x1_grid, y=x2_grid, z=y_grid,\n",
    "    colorscale='Blues',\n",
    "    opacity=0.7,\n",
    "    showscale=False,\n",
    "    name='Superfície de Predição'\n",
    "))\n",
    "\n",
    "# Adicionar pontos originais\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=x1_data,\n",
    "    y=x2_data,\n",
    "    z=y,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=7,\n",
    "        color='red',\n",
    "        symbol='circle',\n",
    "        line=dict(width=1, color='darkred')\n",
    "    ),\n",
    "    name='Dados Originais'\n",
    "))\n",
    "\n",
    "# Adicionar pontos previstos\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=x1_data,\n",
    "    y=x2_data,\n",
    "    z=y_hat,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=7,\n",
    "        color='blue',\n",
    "        symbol='diamond',\n",
    "        line=dict(width=1, color='darkblue')\n",
    "    ),\n",
    "    name='Valores Previstos'\n",
    "))\n",
    "\n",
    "# Adicionar linhas verticais mais finas\n",
    "for i in range(len(x1_data)):\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[x1_data[i], x1_data[i]],\n",
    "        y=[x2_data[i], x2_data[i]],\n",
    "        z=[y[i], y_hat[i]],\n",
    "        mode='lines',\n",
    "        line=dict(color='rgba(0,100,0,0.5)', width=2),\n",
    "        showlegend=False\n",
    "    ))\n",
    "\n",
    "# Configurar layout\n",
    "fig.update_layout(\n",
    "    title='Modelo do Neurônio: Valores Reais vs. Previstos',\n",
    "    scene=dict(\n",
    "        xaxis_title='x1',\n",
    "        yaxis_title='x2',\n",
    "        zaxis_title='y',\n",
    "        # Usar proporções cúbicas para evitar achatamento\n",
    "        aspectmode='cube',\n",
    "        camera=dict(\n",
    "            eye=dict(x=1.5, y=-1.5, z=1),  # Posição da câmera\n",
    "            up=dict(x=0, y=0, z=1)  # Orientação \"para cima\"\n",
    "        ),\n",
    "        xaxis=dict(gridcolor='lightgray'),\n",
    "        yaxis=dict(gridcolor='lightgray'),\n",
    "        zaxis=dict(gridcolor='lightgray')\n",
    "    ),\n",
    "    width=1000,\n",
    "    height=800,\n",
    "    legend=dict(\n",
    "        yanchor=\"top\",\n",
    "        y=0.99,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01,\n",
    "        bgcolor=\"rgba(255,255,255,0.8)\",\n",
    "        bordercolor=\"black\",\n",
    "        borderwidth=1\n",
    "    )\n",
    ")\n",
    "\n",
    "pesos_info = (f\"<b>Neurônio com tanh:</b> w=[{', '.join([f'{w:.4f}' for w in final_denorm_weights])}]<br>\"\n",
    "              f\"MSE: {mse_final:.5f}, RMSE: {rmse_final:.5f}, MAE: {mae_final:.5f}<br>\"\n",
    "              f\"Iterações: {n_iters}\")\n",
    "\n",
    "fig.add_annotation(\n",
    "    x=0.5, y=0.02,\n",
    "    xref=\"paper\", yref=\"paper\",\n",
    "    text=pesos_info,\n",
    "    showarrow=False,\n",
    "    font=dict(size=13),\n",
    "    bgcolor=\"rgba(255, 255, 255, 0.9)\",\n",
    "    bordercolor=\"black\",\n",
    "    borderwidth=1,\n",
    "    borderpad=5\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rna-tarefas-mestrado (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
